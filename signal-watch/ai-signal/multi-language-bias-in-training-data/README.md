# ğŸ¤– Multi-Language Bias in AI Training Data

Behavioral signals used for AI training (recommendation, prediction) are captured only in English â†’ introducing regional/cultural bias.

---

## ğŸš¨ What Happens

- AI training pipelines ingest only English-tagged user events
- Vernacular users (Hindi, Tamil, Bengali, etc.) generate signals that arenâ€™t logged or classified properly
- Resulting models overfit to English-speaking behavior

---

## ğŸ’£ Why Itâ€™s a Problem

- Personalization fails for majority of Indian user base
- Model decisions reflect cultural blind spots
- Violates ethical AI principles and fairness guidelines
- Creates risks under draft Indian AI regulation and global AI Act (EU)

---

## â³ RCA Potential

To be developed into a **flagship RCA** under:  
ğŸ“ `/use-cases/ai-product/signal-aware-ai-fairness-stack/`

---

> â€œAI trained in one language cannot serve a multilingual nation. Bias begins at signal capture â€” not just model weights.â€