# 🤖 Multi-Language Bias in AI Training Data

Behavioral signals used for AI training (recommendation, prediction) are captured only in English → introducing regional/cultural bias.

---

## 🚨 What Happens

- AI training pipelines ingest only English-tagged user events
- Vernacular users (Hindi, Tamil, Bengali, etc.) generate signals that aren’t logged or classified properly
- Resulting models overfit to English-speaking behavior

---

## 💣 Why It’s a Problem

- Personalization fails for majority of Indian user base
- Model decisions reflect cultural blind spots
- Violates ethical AI principles and fairness guidelines
- Creates risks under draft Indian AI regulation and global AI Act (EU)

---

## ⏳ RCA Potential

To be developed into a **flagship RCA** under:  
📁 `/use-cases/ai-product/signal-aware-ai-fairness-stack/`

---

> “AI trained in one language cannot serve a multilingual nation. Bias begins at signal capture — not just model weights.”